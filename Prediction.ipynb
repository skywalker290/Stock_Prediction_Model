{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>8288.700195</td>\n",
       "      <td>8410.599609</td>\n",
       "      <td>8288.700195</td>\n",
       "      <td>8395.450195</td>\n",
       "      <td>8395.450195</td>\n",
       "      <td>101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>8407.950195</td>\n",
       "      <td>8445.599609</td>\n",
       "      <td>8363.900391</td>\n",
       "      <td>8378.400391</td>\n",
       "      <td>8378.400391</td>\n",
       "      <td>118200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>8325.299805</td>\n",
       "      <td>8327.849609</td>\n",
       "      <td>8111.350098</td>\n",
       "      <td>8127.350098</td>\n",
       "      <td>8127.350098</td>\n",
       "      <td>172800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>8118.649902</td>\n",
       "      <td>8151.200195</td>\n",
       "      <td>8065.450195</td>\n",
       "      <td>8102.100098</td>\n",
       "      <td>8102.100098</td>\n",
       "      <td>164100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>8191.399902</td>\n",
       "      <td>8243.500000</td>\n",
       "      <td>8167.299805</td>\n",
       "      <td>8234.599609</td>\n",
       "      <td>8234.599609</td>\n",
       "      <td>143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>12269.250000</td>\n",
       "      <td>12283.700195</td>\n",
       "      <td>12202.099609</td>\n",
       "      <td>12214.549805</td>\n",
       "      <td>12214.549805</td>\n",
       "      <td>470300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>12211.849609</td>\n",
       "      <td>12221.549805</td>\n",
       "      <td>12118.849609</td>\n",
       "      <td>12126.549805</td>\n",
       "      <td>12126.549805</td>\n",
       "      <td>520300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>12172.900391</td>\n",
       "      <td>12258.450195</td>\n",
       "      <td>12157.900391</td>\n",
       "      <td>12245.799805</td>\n",
       "      <td>12245.799805</td>\n",
       "      <td>383800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>12274.900391</td>\n",
       "      <td>12286.450195</td>\n",
       "      <td>12213.799805</td>\n",
       "      <td>12255.849609</td>\n",
       "      <td>12255.849609</td>\n",
       "      <td>411100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>12247.099609</td>\n",
       "      <td>12247.099609</td>\n",
       "      <td>12151.799805</td>\n",
       "      <td>12168.450195</td>\n",
       "      <td>12168.450195</td>\n",
       "      <td>426900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1222 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    open          high           low         close  \\\n",
       "Date                                                                 \n",
       "2015-01-02   8288.700195   8410.599609   8288.700195   8395.450195   \n",
       "2015-01-05   8407.950195   8445.599609   8363.900391   8378.400391   \n",
       "2015-01-06   8325.299805   8327.849609   8111.350098   8127.350098   \n",
       "2015-01-07   8118.649902   8151.200195   8065.450195   8102.100098   \n",
       "2015-01-08   8191.399902   8243.500000   8167.299805   8234.599609   \n",
       "...                  ...           ...           ...           ...   \n",
       "2019-12-24  12269.250000  12283.700195  12202.099609  12214.549805   \n",
       "2019-12-26  12211.849609  12221.549805  12118.849609  12126.549805   \n",
       "2019-12-27  12172.900391  12258.450195  12157.900391  12245.799805   \n",
       "2019-12-30  12274.900391  12286.450195  12213.799805  12255.849609   \n",
       "2019-12-31  12247.099609  12247.099609  12151.799805  12168.450195   \n",
       "\n",
       "               Adj Close  volume  \n",
       "Date                              \n",
       "2015-01-02   8395.450195  101900  \n",
       "2015-01-05   8378.400391  118200  \n",
       "2015-01-06   8127.350098  172800  \n",
       "2015-01-07   8102.100098  164100  \n",
       "2015-01-08   8234.599609  143800  \n",
       "...                  ...     ...  \n",
       "2019-12-24  12214.549805  470300  \n",
       "2019-12-26  12126.549805  520300  \n",
       "2019-12-27  12245.799805  383800  \n",
       "2019-12-30  12255.849609  411100  \n",
       "2019-12-31  12168.450195  426900  \n",
       "\n",
       "[1222 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Replace 'AAPL' with the symbol of another company\n",
    "company = '^NSEI'\n",
    "start = '2015-01-01'\n",
    "end = '2020-01-01'\n",
    "\n",
    "data = yf.download(company, start=start, end=end)\n",
    "data.rename(columns={'Open':'open','High':'high','Low':'low','Close':'close','Volume':'volume'}, inplace= True)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=pd.read_csv('Dec_Feb_ISO.csv')\n",
    "# data=pd.DataFrame(data)\n",
    "# # data=data['time','open','high','low,','close']\n",
    "\n",
    "# selected_columns = ['time','open','high','low','close']\n",
    "\n",
    "# data = data[selected_columns]\n",
    "# data \n",
    "\n",
    "# We are only concerned about the OHLC and volume here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas_ta in /home/skywalker/.local/lib/python3.8/site-packages (0.3.14b0)\n",
      "Requirement already satisfied: pandas in /home/skywalker/.local/lib/python3.8/site-packages (from pandas_ta) (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/skywalker/.local/lib/python3.8/site-packages (from pandas->pandas_ta) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/skywalker/.local/lib/python3.8/site-packages (from pandas->pandas_ta) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/skywalker/.local/lib/python3.8/site-packages (from pandas->pandas_ta) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/skywalker/.local/lib/python3.8/site-packages (from pandas->pandas_ta) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->pandas_ta) (1.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas_ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function dm in module pandas_ta.momentum.dm:\n",
      "\n",
      "dm(high, low, length=None, mamode=None, talib=None, drift=None, offset=None, **kwargs)\n",
      "    Directional Movement (DM)\n",
      "    \n",
      "    The Directional Movement was developed by J. Welles Wilder in 1978 attempts to\n",
      "    determine which direction the price of an asset is moving. It compares prior\n",
      "    highs and lows to yield to two series +DM and -DM.\n",
      "    \n",
      "    Sources:\n",
      "        https://www.tradingview.com/pine-script-reference/#fun_dmi\n",
      "        https://www.sierrachart.com/index.php?page=doc/StudiesReference.php&ID=24&Name=Directional_Movement_Index\n",
      "    \n",
      "    Calculation:\n",
      "        Default Inputs:\n",
      "            length=14, mamode=\"rma\", drift=1\n",
      "                up = high - high.shift(drift)\n",
      "            dn = low.shift(drift) - low\n",
      "    \n",
      "            pos_ = ((up > dn) & (up > 0)) * up\n",
      "            neg_ = ((dn > up) & (dn > 0)) * dn\n",
      "    \n",
      "            pos_ = pos_.apply(zero)\n",
      "            neg_ = neg_.apply(zero)\n",
      "    \n",
      "            # Not the same values as TA Lib's -+DM\n",
      "            pos = ma(mamode, pos_, length=length)\n",
      "            neg = ma(mamode, neg_, length=length)\n",
      "    \n",
      "    Args:\n",
      "        high (pd.Series): Series of 'high's\n",
      "        low (pd.Series): Series of 'low's\n",
      "        mamode (str): See ```help(ta.ma)```.  Default: 'rma'\n",
      "        talib (bool): If TA Lib is installed and talib is True, Returns the TA Lib\n",
      "            version. Default: True\n",
      "        drift (int): The difference period. Default: 1\n",
      "        offset (int): How many periods to offset the result. Default: 0\n",
      "    \n",
      "    Returns:\n",
      "        pd.DataFrame: DMP (+DM) and DMN (-DM) columns.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare Data\n",
    "import pandas_ta as pa\n",
    "\n",
    "help(pa.dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data\n",
    "\n",
    "df['RSI'] = pa.rsi(df.close, length=16)\n",
    "df['CCI'] = pa.cci(df.high, df.low, df.close, length=16)\n",
    "df['AO'] = pa.ao(df.high,df.low)\n",
    "df['MOM'] = pa.mom(df.close,length=16)\n",
    "\n",
    "a = pa.macd(df.close)\n",
    "df = df.join(a)\n",
    "\n",
    "df['ATR'] = pa.atr(df.high, df.low,df.close, length=16)\n",
    "df['BOP'] = pa.bop(df.open, df.high, df.low, df.close, length=16)\n",
    "df['RVI'] = pa.rvi(df.close)\n",
    "\n",
    "a = pa.dm(df.high, df.low, length=16)\n",
    "df = df.join(a)\n",
    "\n",
    "a = pa.stoch(df.high, df.low, df.close)\n",
    "df = df.join(a)\n",
    "\n",
    "a = pa.stochrsi(df.close, length=16)\n",
    "df = df.join(a)\n",
    "\n",
    "df[\"WPR\"] = pa.willr(df.high, df.low, df.close, length=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>volume</th>\n",
       "      <th>RSI</th>\n",
       "      <th>CCI</th>\n",
       "      <th>AO</th>\n",
       "      <th>MOM</th>\n",
       "      <th>...</th>\n",
       "      <th>ATR</th>\n",
       "      <th>BOP</th>\n",
       "      <th>RVI</th>\n",
       "      <th>DMP_16</th>\n",
       "      <th>DMN_16</th>\n",
       "      <th>STOCHk_14_3_3</th>\n",
       "      <th>STOCHd_14_3_3</th>\n",
       "      <th>STOCHRSIk_16_14_3_3</th>\n",
       "      <th>STOCHRSId_16_14_3_3</th>\n",
       "      <th>WPR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>8288.700195</td>\n",
       "      <td>8410.599609</td>\n",
       "      <td>8288.700195</td>\n",
       "      <td>8395.450195</td>\n",
       "      <td>8395.450195</td>\n",
       "      <td>101900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>8407.950195</td>\n",
       "      <td>8445.599609</td>\n",
       "      <td>8363.900391</td>\n",
       "      <td>8378.400391</td>\n",
       "      <td>8378.400391</td>\n",
       "      <td>118200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.361690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>8325.299805</td>\n",
       "      <td>8327.849609</td>\n",
       "      <td>8111.350098</td>\n",
       "      <td>8127.350098</td>\n",
       "      <td>8127.350098</td>\n",
       "      <td>172800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.914319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>8118.649902</td>\n",
       "      <td>8151.200195</td>\n",
       "      <td>8065.450195</td>\n",
       "      <td>8102.100098</td>\n",
       "      <td>8102.100098</td>\n",
       "      <td>164100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>8191.399902</td>\n",
       "      <td>8243.500000</td>\n",
       "      <td>8167.299805</td>\n",
       "      <td>8234.599609</td>\n",
       "      <td>8234.599609</td>\n",
       "      <td>143800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.566924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>12269.250000</td>\n",
       "      <td>12283.700195</td>\n",
       "      <td>12202.099609</td>\n",
       "      <td>12214.549805</td>\n",
       "      <td>12214.549805</td>\n",
       "      <td>470300</td>\n",
       "      <td>62.071537</td>\n",
       "      <td>93.668239</td>\n",
       "      <td>215.833869</td>\n",
       "      <td>166.349609</td>\n",
       "      <td>...</td>\n",
       "      <td>101.057537</td>\n",
       "      <td>-0.670341</td>\n",
       "      <td>51.261064</td>\n",
       "      <td>27.924891</td>\n",
       "      <td>16.983204</td>\n",
       "      <td>90.424509</td>\n",
       "      <td>94.113709</td>\n",
       "      <td>90.623885</td>\n",
       "      <td>93.072524</td>\n",
       "      <td>-17.190313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>12211.849609</td>\n",
       "      <td>12221.549805</td>\n",
       "      <td>12118.849609</td>\n",
       "      <td>12126.549805</td>\n",
       "      <td>12126.549805</td>\n",
       "      <td>520300</td>\n",
       "      <td>56.068696</td>\n",
       "      <td>41.985749</td>\n",
       "      <td>202.593345</td>\n",
       "      <td>132.349609</td>\n",
       "      <td>...</td>\n",
       "      <td>101.160203</td>\n",
       "      <td>-0.830571</td>\n",
       "      <td>42.364715</td>\n",
       "      <td>26.179586</td>\n",
       "      <td>21.124879</td>\n",
       "      <td>79.935643</td>\n",
       "      <td>88.617857</td>\n",
       "      <td>71.411676</td>\n",
       "      <td>86.050378</td>\n",
       "      <td>-36.254414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>12172.900391</td>\n",
       "      <td>12258.450195</td>\n",
       "      <td>12157.900391</td>\n",
       "      <td>12245.799805</td>\n",
       "      <td>12245.799805</td>\n",
       "      <td>383800</td>\n",
       "      <td>61.456589</td>\n",
       "      <td>69.603829</td>\n",
       "      <td>191.688689</td>\n",
       "      <td>202.599609</td>\n",
       "      <td>...</td>\n",
       "      <td>103.081465</td>\n",
       "      <td>0.725008</td>\n",
       "      <td>51.814667</td>\n",
       "      <td>26.849636</td>\n",
       "      <td>19.804574</td>\n",
       "      <td>78.711627</td>\n",
       "      <td>83.023927</td>\n",
       "      <td>63.479206</td>\n",
       "      <td>75.171589</td>\n",
       "      <td>-10.420391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>12274.900391</td>\n",
       "      <td>12286.450195</td>\n",
       "      <td>12213.799805</td>\n",
       "      <td>12255.849609</td>\n",
       "      <td>12255.849609</td>\n",
       "      <td>411100</td>\n",
       "      <td>61.876891</td>\n",
       "      <td>76.838908</td>\n",
       "      <td>178.558215</td>\n",
       "      <td>237.449219</td>\n",
       "      <td>...</td>\n",
       "      <td>101.179523</td>\n",
       "      <td>-0.262225</td>\n",
       "      <td>59.266529</td>\n",
       "      <td>26.921534</td>\n",
       "      <td>18.566788</td>\n",
       "      <td>81.693990</td>\n",
       "      <td>80.113753</td>\n",
       "      <td>63.124733</td>\n",
       "      <td>66.005205</td>\n",
       "      <td>-8.243226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>12247.099609</td>\n",
       "      <td>12247.099609</td>\n",
       "      <td>12151.799805</td>\n",
       "      <td>12168.450195</td>\n",
       "      <td>12168.450195</td>\n",
       "      <td>426900</td>\n",
       "      <td>56.192678</td>\n",
       "      <td>37.457825</td>\n",
       "      <td>159.403722</td>\n",
       "      <td>246.950195</td>\n",
       "      <td>...</td>\n",
       "      <td>101.358916</td>\n",
       "      <td>-0.825284</td>\n",
       "      <td>51.701651</td>\n",
       "      <td>25.238938</td>\n",
       "      <td>21.281364</td>\n",
       "      <td>84.719722</td>\n",
       "      <td>81.708446</td>\n",
       "      <td>63.460615</td>\n",
       "      <td>63.354851</td>\n",
       "      <td>-27.177218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1222 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    open          high           low         close  \\\n",
       "Date                                                                 \n",
       "2015-01-02   8288.700195   8410.599609   8288.700195   8395.450195   \n",
       "2015-01-05   8407.950195   8445.599609   8363.900391   8378.400391   \n",
       "2015-01-06   8325.299805   8327.849609   8111.350098   8127.350098   \n",
       "2015-01-07   8118.649902   8151.200195   8065.450195   8102.100098   \n",
       "2015-01-08   8191.399902   8243.500000   8167.299805   8234.599609   \n",
       "...                  ...           ...           ...           ...   \n",
       "2019-12-24  12269.250000  12283.700195  12202.099609  12214.549805   \n",
       "2019-12-26  12211.849609  12221.549805  12118.849609  12126.549805   \n",
       "2019-12-27  12172.900391  12258.450195  12157.900391  12245.799805   \n",
       "2019-12-30  12274.900391  12286.450195  12213.799805  12255.849609   \n",
       "2019-12-31  12247.099609  12247.099609  12151.799805  12168.450195   \n",
       "\n",
       "               Adj Close  volume        RSI        CCI          AO  \\\n",
       "Date                                                                 \n",
       "2015-01-02   8395.450195  101900        NaN        NaN         NaN   \n",
       "2015-01-05   8378.400391  118200        NaN        NaN         NaN   \n",
       "2015-01-06   8127.350098  172800        NaN        NaN         NaN   \n",
       "2015-01-07   8102.100098  164100        NaN        NaN         NaN   \n",
       "2015-01-08   8234.599609  143800        NaN        NaN         NaN   \n",
       "...                  ...     ...        ...        ...         ...   \n",
       "2019-12-24  12214.549805  470300  62.071537  93.668239  215.833869   \n",
       "2019-12-26  12126.549805  520300  56.068696  41.985749  202.593345   \n",
       "2019-12-27  12245.799805  383800  61.456589  69.603829  191.688689   \n",
       "2019-12-30  12255.849609  411100  61.876891  76.838908  178.558215   \n",
       "2019-12-31  12168.450195  426900  56.192678  37.457825  159.403722   \n",
       "\n",
       "                   MOM  ...         ATR       BOP        RVI     DMP_16  \\\n",
       "Date                    ...                                               \n",
       "2015-01-02         NaN  ...         NaN  0.875722        NaN        NaN   \n",
       "2015-01-05         NaN  ...         NaN -0.361690        NaN        NaN   \n",
       "2015-01-06         NaN  ...         NaN -0.914319        NaN        NaN   \n",
       "2015-01-07         NaN  ...         NaN -0.193001        NaN        NaN   \n",
       "2015-01-08         NaN  ...         NaN  0.566924        NaN        NaN   \n",
       "...                ...  ...         ...       ...        ...        ...   \n",
       "2019-12-24  166.349609  ...  101.057537 -0.670341  51.261064  27.924891   \n",
       "2019-12-26  132.349609  ...  101.160203 -0.830571  42.364715  26.179586   \n",
       "2019-12-27  202.599609  ...  103.081465  0.725008  51.814667  26.849636   \n",
       "2019-12-30  237.449219  ...  101.179523 -0.262225  59.266529  26.921534   \n",
       "2019-12-31  246.950195  ...  101.358916 -0.825284  51.701651  25.238938   \n",
       "\n",
       "               DMN_16  STOCHk_14_3_3  STOCHd_14_3_3  STOCHRSIk_16_14_3_3  \\\n",
       "Date                                                                       \n",
       "2015-01-02        NaN            NaN            NaN                  NaN   \n",
       "2015-01-05        NaN            NaN            NaN                  NaN   \n",
       "2015-01-06        NaN            NaN            NaN                  NaN   \n",
       "2015-01-07        NaN            NaN            NaN                  NaN   \n",
       "2015-01-08        NaN            NaN            NaN                  NaN   \n",
       "...               ...            ...            ...                  ...   \n",
       "2019-12-24  16.983204      90.424509      94.113709            90.623885   \n",
       "2019-12-26  21.124879      79.935643      88.617857            71.411676   \n",
       "2019-12-27  19.804574      78.711627      83.023927            63.479206   \n",
       "2019-12-30  18.566788      81.693990      80.113753            63.124733   \n",
       "2019-12-31  21.281364      84.719722      81.708446            63.460615   \n",
       "\n",
       "            STOCHRSId_16_14_3_3        WPR  \n",
       "Date                                        \n",
       "2015-01-02                  NaN        NaN  \n",
       "2015-01-05                  NaN        NaN  \n",
       "2015-01-06                  NaN        NaN  \n",
       "2015-01-07                  NaN        NaN  \n",
       "2015-01-08                  NaN        NaN  \n",
       "...                         ...        ...  \n",
       "2019-12-24            93.072524 -17.190313  \n",
       "2019-12-26            86.050378 -36.254414  \n",
       "2019-12-27            75.171589 -10.420391  \n",
       "2019-12-30            66.005205  -8.243226  \n",
       "2019-12-31            63.354851 -27.177218  \n",
       "\n",
       "[1222 rows x 23 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open                   0\n",
       "high                   0\n",
       "low                    0\n",
       "close                  0\n",
       "Adj Close              0\n",
       "volume                 0\n",
       "RSI                    0\n",
       "CCI                    0\n",
       "AO                     0\n",
       "MOM                    0\n",
       "MACD_12_26_9           0\n",
       "MACDh_12_26_9          0\n",
       "MACDs_12_26_9          0\n",
       "ATR                    0\n",
       "BOP                    0\n",
       "RVI                    0\n",
       "DMP_16                 0\n",
       "DMN_16                 0\n",
       "STOCHk_14_3_3          0\n",
       "STOCHd_14_3_3          0\n",
       "STOCHRSIk_16_14_3_3    0\n",
       "STOCHRSId_16_14_3_3    0\n",
       "WPR                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clear NA values\n",
    "\n",
    "df.isna().sum()\n",
    "df.dropna(inplace=True)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>volume</th>\n",
       "      <th>RSI</th>\n",
       "      <th>CCI</th>\n",
       "      <th>AO</th>\n",
       "      <th>MOM</th>\n",
       "      <th>...</th>\n",
       "      <th>ATR</th>\n",
       "      <th>BOP</th>\n",
       "      <th>RVI</th>\n",
       "      <th>DMP_16</th>\n",
       "      <th>DMN_16</th>\n",
       "      <th>STOCHk_14_3_3</th>\n",
       "      <th>STOCHd_14_3_3</th>\n",
       "      <th>STOCHRSIk_16_14_3_3</th>\n",
       "      <th>STOCHRSId_16_14_3_3</th>\n",
       "      <th>WPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>12269.250000</td>\n",
       "      <td>12283.700195</td>\n",
       "      <td>12202.099609</td>\n",
       "      <td>12214.549805</td>\n",
       "      <td>12214.549805</td>\n",
       "      <td>470300</td>\n",
       "      <td>62.071537</td>\n",
       "      <td>93.668239</td>\n",
       "      <td>215.833869</td>\n",
       "      <td>166.349609</td>\n",
       "      <td>...</td>\n",
       "      <td>101.057537</td>\n",
       "      <td>-0.670341</td>\n",
       "      <td>51.261064</td>\n",
       "      <td>27.924891</td>\n",
       "      <td>16.983204</td>\n",
       "      <td>90.424509</td>\n",
       "      <td>94.113709</td>\n",
       "      <td>90.623885</td>\n",
       "      <td>93.072524</td>\n",
       "      <td>-17.190313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>12211.849609</td>\n",
       "      <td>12221.549805</td>\n",
       "      <td>12118.849609</td>\n",
       "      <td>12126.549805</td>\n",
       "      <td>12126.549805</td>\n",
       "      <td>520300</td>\n",
       "      <td>56.068696</td>\n",
       "      <td>41.985749</td>\n",
       "      <td>202.593345</td>\n",
       "      <td>132.349609</td>\n",
       "      <td>...</td>\n",
       "      <td>101.160203</td>\n",
       "      <td>-0.830571</td>\n",
       "      <td>42.364715</td>\n",
       "      <td>26.179586</td>\n",
       "      <td>21.124879</td>\n",
       "      <td>79.935643</td>\n",
       "      <td>88.617857</td>\n",
       "      <td>71.411676</td>\n",
       "      <td>86.050378</td>\n",
       "      <td>-36.254414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>12172.900391</td>\n",
       "      <td>12258.450195</td>\n",
       "      <td>12157.900391</td>\n",
       "      <td>12245.799805</td>\n",
       "      <td>12245.799805</td>\n",
       "      <td>383800</td>\n",
       "      <td>61.456589</td>\n",
       "      <td>69.603829</td>\n",
       "      <td>191.688689</td>\n",
       "      <td>202.599609</td>\n",
       "      <td>...</td>\n",
       "      <td>103.081465</td>\n",
       "      <td>0.725008</td>\n",
       "      <td>51.814667</td>\n",
       "      <td>26.849636</td>\n",
       "      <td>19.804574</td>\n",
       "      <td>78.711627</td>\n",
       "      <td>83.023927</td>\n",
       "      <td>63.479206</td>\n",
       "      <td>75.171589</td>\n",
       "      <td>-10.420391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>12274.900391</td>\n",
       "      <td>12286.450195</td>\n",
       "      <td>12213.799805</td>\n",
       "      <td>12255.849609</td>\n",
       "      <td>12255.849609</td>\n",
       "      <td>411100</td>\n",
       "      <td>61.876891</td>\n",
       "      <td>76.838908</td>\n",
       "      <td>178.558215</td>\n",
       "      <td>237.449219</td>\n",
       "      <td>...</td>\n",
       "      <td>101.179523</td>\n",
       "      <td>-0.262225</td>\n",
       "      <td>59.266529</td>\n",
       "      <td>26.921534</td>\n",
       "      <td>18.566788</td>\n",
       "      <td>81.693990</td>\n",
       "      <td>80.113753</td>\n",
       "      <td>63.124733</td>\n",
       "      <td>66.005205</td>\n",
       "      <td>-8.243226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>12247.099609</td>\n",
       "      <td>12247.099609</td>\n",
       "      <td>12151.799805</td>\n",
       "      <td>12168.450195</td>\n",
       "      <td>12168.450195</td>\n",
       "      <td>426900</td>\n",
       "      <td>56.192678</td>\n",
       "      <td>37.457825</td>\n",
       "      <td>159.403722</td>\n",
       "      <td>246.950195</td>\n",
       "      <td>...</td>\n",
       "      <td>101.358916</td>\n",
       "      <td>-0.825284</td>\n",
       "      <td>51.701651</td>\n",
       "      <td>25.238938</td>\n",
       "      <td>21.281364</td>\n",
       "      <td>84.719722</td>\n",
       "      <td>81.708446</td>\n",
       "      <td>63.460615</td>\n",
       "      <td>63.354851</td>\n",
       "      <td>-27.177218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              open          high           low         close     Adj Close  \\\n",
       "1184  12269.250000  12283.700195  12202.099609  12214.549805  12214.549805   \n",
       "1185  12211.849609  12221.549805  12118.849609  12126.549805  12126.549805   \n",
       "1186  12172.900391  12258.450195  12157.900391  12245.799805  12245.799805   \n",
       "1187  12274.900391  12286.450195  12213.799805  12255.849609  12255.849609   \n",
       "1188  12247.099609  12247.099609  12151.799805  12168.450195  12168.450195   \n",
       "\n",
       "      volume        RSI        CCI          AO         MOM  ...         ATR  \\\n",
       "1184  470300  62.071537  93.668239  215.833869  166.349609  ...  101.057537   \n",
       "1185  520300  56.068696  41.985749  202.593345  132.349609  ...  101.160203   \n",
       "1186  383800  61.456589  69.603829  191.688689  202.599609  ...  103.081465   \n",
       "1187  411100  61.876891  76.838908  178.558215  237.449219  ...  101.179523   \n",
       "1188  426900  56.192678  37.457825  159.403722  246.950195  ...  101.358916   \n",
       "\n",
       "           BOP        RVI     DMP_16     DMN_16  STOCHk_14_3_3  STOCHd_14_3_3  \\\n",
       "1184 -0.670341  51.261064  27.924891  16.983204      90.424509      94.113709   \n",
       "1185 -0.830571  42.364715  26.179586  21.124879      79.935643      88.617857   \n",
       "1186  0.725008  51.814667  26.849636  19.804574      78.711627      83.023927   \n",
       "1187 -0.262225  59.266529  26.921534  18.566788      81.693990      80.113753   \n",
       "1188 -0.825284  51.701651  25.238938  21.281364      84.719722      81.708446   \n",
       "\n",
       "      STOCHRSIk_16_14_3_3  STOCHRSId_16_14_3_3        WPR  \n",
       "1184            90.623885            93.072524 -17.190313  \n",
       "1185            71.411676            86.050378 -36.254414  \n",
       "1186            63.479206            75.171589 -10.420391  \n",
       "1187            63.124733            66.005205  -8.243226  \n",
       "1188            63.460615            63.354851 -27.177218  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the index\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target flexible way\n",
    "# Calculates if the trend is an uptrend of a downtrend\n",
    "pipdiff = 200*1e-4 #for TP\n",
    "pipdiff = 100 #for TP\n",
    "SLTPRatio = 2 #pipdiff/Ratio gives SL\n",
    "def mytarget(barsupfront, df1):\n",
    "    length = len(df1)\n",
    "    high = list(df1['high'])\n",
    "    low = list(df1['low'])\n",
    "    close = list(df1['close'])\n",
    "    open = list(df1['open'])\n",
    "    trendcat = [None] * length\n",
    "    for line in range (0,length-barsupfront-2):\n",
    "        valueOpenLow = 0\n",
    "        valueOpenHigh = 0\n",
    "        for i in range(1,barsupfront+2):\n",
    "            value1 = open[line+1]-low[line+i]\n",
    "            value2 = open[line+1]-high[line+i]\n",
    "            valueOpenLow = max(value1, valueOpenLow)\n",
    "            valueOpenHigh = min(value2, valueOpenHigh)\n",
    "        #if ( (valueOpenLow >= (pipdiff/SLTPRatio)) and (-valueOpenHigh >= (pipdiff/SLTPRatio)) ):\n",
    "        #    trendcat[line] = 2 # bth limits exceeded\n",
    "        #elif ( (valueOpenLow >= pipdiff) and (-valueOpenHigh <= (pipdiff/SLTPRatio)) ):\n",
    "        #    trendcat[line] = 3 #-1 downtrend\n",
    "        #elif ( (valueOpenLow <= (pipdiff/SLTPRatio)) and (-valueOpenHigh >= pipdiff) ):\n",
    "        #    trendcat[line] = 1 # uptrend\n",
    "        #elif ( (valueOpenLow <= (pipdiff/SLTPRatio)) and (-valueOpenHigh <= (pipdiff/SLTPRatio)) ):\n",
    "        #    trendcat[line] = 0 # no trend\n",
    "        #elif ( (valueOpenLow >= (pipdiff/SLTPRatio)) and (-valueOpenHigh <= (pipdiff/SLTPRatio)) ):\n",
    "        #    trendcat[line] = 5 # light trend down\n",
    "        #elif ( (valueOpenLow <= (pipdiff/SLTPRatio)) and (-valueOpenHigh >= (pipdiff/SLTPRatio)) ):\n",
    "        #    trendcat[line] = 4 # light trend up\n",
    "            if ( (valueOpenLow >= pipdiff) and (-valueOpenHigh <= (pipdiff/SLTPRatio)) ):\n",
    "                trendcat[line] = 1 #-1 downtrend\n",
    "                break\n",
    "            elif ( (valueOpenLow <= (pipdiff/SLTPRatio)) and (-valueOpenHigh >= pipdiff) ):\n",
    "                trendcat[line] = 2 # uptrend\n",
    "                break\n",
    "            else:\n",
    "                trendcat[line] = 0 # no clear trend\n",
    "            \n",
    "    return trendcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open                   0\n",
       "high                   0\n",
       "low                    0\n",
       "close                  0\n",
       "Adj Close              0\n",
       "volume                 0\n",
       "RSI                    0\n",
       "CCI                    0\n",
       "AO                     0\n",
       "MOM                    0\n",
       "MACD_12_26_9           0\n",
       "MACDh_12_26_9          0\n",
       "MACDs_12_26_9          0\n",
       "ATR                    0\n",
       "BOP                    0\n",
       "RVI                    0\n",
       "DMP_16                 0\n",
       "DMN_16                 0\n",
       "STOCHk_14_3_3          0\n",
       "STOCHd_14_3_3          0\n",
       "STOCHRSIk_16_14_3_3    0\n",
       "STOCHRSId_16_14_3_3    0\n",
       "WPR                    0\n",
       "Target                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Target']=mytarget(20,df)\n",
    "df['Target'].hist()\n",
    "df.isna().sum()\n",
    "df.dropna(inplace=True)\n",
    "df.isna().sum()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>volume</th>\n",
       "      <th>RSI</th>\n",
       "      <th>CCI</th>\n",
       "      <th>AO</th>\n",
       "      <th>MOM</th>\n",
       "      <th>...</th>\n",
       "      <th>BOP</th>\n",
       "      <th>RVI</th>\n",
       "      <th>DMP_16</th>\n",
       "      <th>DMN_16</th>\n",
       "      <th>STOCHk_14_3_3</th>\n",
       "      <th>STOCHd_14_3_3</th>\n",
       "      <th>STOCHRSIk_16_14_3_3</th>\n",
       "      <th>STOCHRSId_16_14_3_3</th>\n",
       "      <th>WPR</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>10994.849609</td>\n",
       "      <td>11052.700195</td>\n",
       "      <td>10968.200195</td>\n",
       "      <td>11003.500000</td>\n",
       "      <td>11003.500000</td>\n",
       "      <td>434500</td>\n",
       "      <td>47.997895</td>\n",
       "      <td>50.190975</td>\n",
       "      <td>11.617963</td>\n",
       "      <td>84.799805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102371</td>\n",
       "      <td>60.929800</td>\n",
       "      <td>24.892900</td>\n",
       "      <td>35.780967</td>\n",
       "      <td>73.495102</td>\n",
       "      <td>74.990498</td>\n",
       "      <td>90.291412</td>\n",
       "      <td>93.394059</td>\n",
       "      <td>-27.397960</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>11000.099609</td>\n",
       "      <td>11000.099609</td>\n",
       "      <td>10796.500000</td>\n",
       "      <td>10817.599609</td>\n",
       "      <td>10817.599609</td>\n",
       "      <td>482000</td>\n",
       "      <td>41.658189</td>\n",
       "      <td>-69.507517</td>\n",
       "      <td>11.238724</td>\n",
       "      <td>76.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.896367</td>\n",
       "      <td>53.501953</td>\n",
       "      <td>23.337093</td>\n",
       "      <td>44.275919</td>\n",
       "      <td>56.668426</td>\n",
       "      <td>69.435981</td>\n",
       "      <td>71.295683</td>\n",
       "      <td>85.778785</td>\n",
       "      <td>-64.239128</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>10872.799805</td>\n",
       "      <td>10885.150391</td>\n",
       "      <td>10804.849609</td>\n",
       "      <td>10840.650391</td>\n",
       "      <td>10840.650391</td>\n",
       "      <td>519200</td>\n",
       "      <td>42.659893</td>\n",
       "      <td>-104.704579</td>\n",
       "      <td>-14.234981</td>\n",
       "      <td>11.300781</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400362</td>\n",
       "      <td>59.026507</td>\n",
       "      <td>21.878525</td>\n",
       "      <td>41.508674</td>\n",
       "      <td>35.885815</td>\n",
       "      <td>55.349781</td>\n",
       "      <td>46.507766</td>\n",
       "      <td>69.364954</td>\n",
       "      <td>-76.150559</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>10845.200195</td>\n",
       "      <td>10845.200195</td>\n",
       "      <td>10670.250000</td>\n",
       "      <td>10704.799805</td>\n",
       "      <td>10704.799805</td>\n",
       "      <td>642600</td>\n",
       "      <td>38.503951</td>\n",
       "      <td>-156.285003</td>\n",
       "      <td>-53.420269</td>\n",
       "      <td>-353.049805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.802516</td>\n",
       "      <td>50.982691</td>\n",
       "      <td>20.511117</td>\n",
       "      <td>47.326857</td>\n",
       "      <td>16.987777</td>\n",
       "      <td>36.514006</td>\n",
       "      <td>18.632281</td>\n",
       "      <td>45.478577</td>\n",
       "      <td>-92.672364</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>10746.799805</td>\n",
       "      <td>11381.900391</td>\n",
       "      <td>10691.000000</td>\n",
       "      <td>11274.200195</td>\n",
       "      <td>11274.200195</td>\n",
       "      <td>1356800</td>\n",
       "      <td>57.161930</td>\n",
       "      <td>133.164783</td>\n",
       "      <td>-45.220835</td>\n",
       "      <td>168.850586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763352</td>\n",
       "      <td>59.423555</td>\n",
       "      <td>52.772935</td>\n",
       "      <td>44.368929</td>\n",
       "      <td>39.269920</td>\n",
       "      <td>30.714504</td>\n",
       "      <td>41.878750</td>\n",
       "      <td>35.672932</td>\n",
       "      <td>-15.133863</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              open          high           low         close     Adj Close  \\\n",
       "1118  10994.849609  11052.700195  10968.200195  11003.500000  11003.500000   \n",
       "1119  11000.099609  11000.099609  10796.500000  10817.599609  10817.599609   \n",
       "1120  10872.799805  10885.150391  10804.849609  10840.650391  10840.650391   \n",
       "1121  10845.200195  10845.200195  10670.250000  10704.799805  10704.799805   \n",
       "1122  10746.799805  11381.900391  10691.000000  11274.200195  11274.200195   \n",
       "\n",
       "       volume        RSI         CCI         AO         MOM  ...       BOP  \\\n",
       "1118   434500  47.997895   50.190975  11.617963   84.799805  ...  0.102371   \n",
       "1119   482000  41.658189  -69.507517  11.238724   76.250000  ... -0.896367   \n",
       "1120   519200  42.659893 -104.704579 -14.234981   11.300781  ... -0.400362   \n",
       "1121   642600  38.503951 -156.285003 -53.420269 -353.049805  ... -0.802516   \n",
       "1122  1356800  57.161930  133.164783 -45.220835  168.850586  ...  0.763352   \n",
       "\n",
       "            RVI     DMP_16     DMN_16  STOCHk_14_3_3  STOCHd_14_3_3  \\\n",
       "1118  60.929800  24.892900  35.780967      73.495102      74.990498   \n",
       "1119  53.501953  23.337093  44.275919      56.668426      69.435981   \n",
       "1120  59.026507  21.878525  41.508674      35.885815      55.349781   \n",
       "1121  50.982691  20.511117  47.326857      16.987777      36.514006   \n",
       "1122  59.423555  52.772935  44.368929      39.269920      30.714504   \n",
       "\n",
       "      STOCHRSIk_16_14_3_3  STOCHRSId_16_14_3_3        WPR  Target  \n",
       "1118            90.291412            93.394059 -27.397960     1.0  \n",
       "1119            71.295683            85.778785 -64.239128     1.0  \n",
       "1120            46.507766            69.364954 -76.150559     1.0  \n",
       "1121            18.632281            45.478577 -92.672364     0.0  \n",
       "1122            41.878750            35.672932 -15.133863     0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/skywalker/.local/lib/python3.8/site-packages (2.0.2)\n",
      "Requirement already satisfied: scipy in /home/skywalker/.local/lib/python3.8/site-packages (from xgboost) (1.10.1)\n",
      "Requirement already satisfied: numpy in /home/skywalker/.local/lib/python3.8/site-packages (from xgboost) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Train Results****\n",
      "Accuracy: 100.0000%\n",
      "****Test Results****\n",
      "Accuracy: 33.7778%\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "attributes = ['RSI', 'CCI', 'AO', 'MOM', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9', 'ATR',\n",
    "       'BOP', 'RVI', 'DMP_16', 'DMN_16', 'STOCHk_14_3_3', 'STOCHd_14_3_3',\n",
    "       'STOCHRSIk_16_14_3_3', 'STOCHRSId_16_14_3_3', 'WPR'] # All the indicators Are here\n",
    "\n",
    "\n",
    "# attributes = ['RSI', 'CCI', 'BOP', 'STOCHRSIk_16_14_3_3', 'WPR']\n",
    "\n",
    "X = df[attributes]\n",
    "y = df['Target']\n",
    "\n",
    "train_pct_index = int(0.6 * len(X))\n",
    "X_train, X_test = X[:train_pct_index], X[train_pct_index:]\n",
    "y_train, y_test = y[:train_pct_index], y[train_pct_index:]\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "pred_train = model.predict(X_train)\n",
    "pred_test = model.predict(X_test)\n",
    "\n",
    "acc_train = accuracy_score(y_train, pred_train)\n",
    "acc_test = accuracy_score(y_test, pred_test)\n",
    "print('****Train Results****')\n",
    "print(\"Accuracy: {:.4%}\".format(acc_train))\n",
    "print('****Test Results****')\n",
    "print(\"Accuracy: {:.4%}\".format(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_model.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "joblib.dump(model, 'xgb_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RSI</th>\n",
       "      <th>CCI</th>\n",
       "      <th>BOP</th>\n",
       "      <th>STOCHRSIk_16_14_3_3</th>\n",
       "      <th>WPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>74.937097</td>\n",
       "      <td>137.571804</td>\n",
       "      <td>0.614928</td>\n",
       "      <td>82.359265</td>\n",
       "      <td>-8.059361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>76.563639</td>\n",
       "      <td>148.574454</td>\n",
       "      <td>0.216399</td>\n",
       "      <td>89.157122</td>\n",
       "      <td>-3.988340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>72.154098</td>\n",
       "      <td>119.931561</td>\n",
       "      <td>-0.655113</td>\n",
       "      <td>85.535038</td>\n",
       "      <td>-16.093018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>64.095067</td>\n",
       "      <td>60.065457</td>\n",
       "      <td>-0.814230</td>\n",
       "      <td>54.292874</td>\n",
       "      <td>-35.916509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>67.138816</td>\n",
       "      <td>63.417185</td>\n",
       "      <td>0.665138</td>\n",
       "      <td>29.089527</td>\n",
       "      <td>-20.662018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>59.783809</td>\n",
       "      <td>-5.503586</td>\n",
       "      <td>-0.625291</td>\n",
       "      <td>30.349118</td>\n",
       "      <td>-52.638114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>65.967804</td>\n",
       "      <td>163.859146</td>\n",
       "      <td>0.918360</td>\n",
       "      <td>31.165432</td>\n",
       "      <td>-3.814091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>63.607557</td>\n",
       "      <td>177.323377</td>\n",
       "      <td>-0.574938</td>\n",
       "      <td>31.514506</td>\n",
       "      <td>-28.729550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>65.882984</td>\n",
       "      <td>167.818194</td>\n",
       "      <td>0.538915</td>\n",
       "      <td>50.573829</td>\n",
       "      <td>-9.627052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>67.612710</td>\n",
       "      <td>172.841869</td>\n",
       "      <td>0.323720</td>\n",
       "      <td>55.422956</td>\n",
       "      <td>-2.147810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            RSI         CCI       BOP  STOCHRSIk_16_14_3_3        WPR\n",
       "1327  74.937097  137.571804  0.614928            82.359265  -8.059361\n",
       "1328  76.563639  148.574454  0.216399            89.157122  -3.988340\n",
       "1329  72.154098  119.931561 -0.655113            85.535038 -16.093018\n",
       "1330  64.095067   60.065457 -0.814230            54.292874 -35.916509\n",
       "1331  67.138816   63.417185  0.665138            29.089527 -20.662018\n",
       "...         ...         ...       ...                  ...        ...\n",
       "1891  59.783809   -5.503586 -0.625291            30.349118 -52.638114\n",
       "1892  65.967804  163.859146  0.918360            31.165432  -3.814091\n",
       "1893  63.607557  177.323377 -0.574938            31.514506 -28.729550\n",
       "1894  65.882984  167.818194  0.538915            50.573829  -9.627052\n",
       "1895  67.612710  172.841869  0.323720            55.422956  -2.147810\n",
       "\n",
       "[569 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the Furthure Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>12202.150391</td>\n",
       "      <td>12222.200195</td>\n",
       "      <td>12165.299805</td>\n",
       "      <td>12182.500000</td>\n",
       "      <td>12182.500000</td>\n",
       "      <td>304100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>12198.549805</td>\n",
       "      <td>12289.900391</td>\n",
       "      <td>12195.250000</td>\n",
       "      <td>12282.200195</td>\n",
       "      <td>12282.200195</td>\n",
       "      <td>407700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>12261.099609</td>\n",
       "      <td>12265.599609</td>\n",
       "      <td>12191.349609</td>\n",
       "      <td>12226.650391</td>\n",
       "      <td>12226.650391</td>\n",
       "      <td>428800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>12170.599609</td>\n",
       "      <td>12179.099609</td>\n",
       "      <td>11974.200195</td>\n",
       "      <td>11993.049805</td>\n",
       "      <td>11993.049805</td>\n",
       "      <td>396500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>12079.099609</td>\n",
       "      <td>12152.150391</td>\n",
       "      <td>12005.349609</td>\n",
       "      <td>12052.950195</td>\n",
       "      <td>12052.950195</td>\n",
       "      <td>447800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <td>16937.750000</td>\n",
       "      <td>17112.050781</td>\n",
       "      <td>16833.199219</td>\n",
       "      <td>17086.250000</td>\n",
       "      <td>17086.250000</td>\n",
       "      <td>144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>17177.599609</td>\n",
       "      <td>17250.250000</td>\n",
       "      <td>17161.150391</td>\n",
       "      <td>17233.250000</td>\n",
       "      <td>17233.250000</td>\n",
       "      <td>176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <td>17220.099609</td>\n",
       "      <td>17285.949219</td>\n",
       "      <td>17176.650391</td>\n",
       "      <td>17213.599609</td>\n",
       "      <td>17213.599609</td>\n",
       "      <td>161700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30</th>\n",
       "      <td>17201.449219</td>\n",
       "      <td>17264.050781</td>\n",
       "      <td>17146.349609</td>\n",
       "      <td>17203.949219</td>\n",
       "      <td>17203.949219</td>\n",
       "      <td>320800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>17244.500000</td>\n",
       "      <td>17400.800781</td>\n",
       "      <td>17238.500000</td>\n",
       "      <td>17354.050781</td>\n",
       "      <td>17354.050781</td>\n",
       "      <td>167000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    open          high           low         close  \\\n",
       "Date                                                                 \n",
       "2020-01-01  12202.150391  12222.200195  12165.299805  12182.500000   \n",
       "2020-01-02  12198.549805  12289.900391  12195.250000  12282.200195   \n",
       "2020-01-03  12261.099609  12265.599609  12191.349609  12226.650391   \n",
       "2020-01-06  12170.599609  12179.099609  11974.200195  11993.049805   \n",
       "2020-01-07  12079.099609  12152.150391  12005.349609  12052.950195   \n",
       "...                  ...           ...           ...           ...   \n",
       "2021-12-27  16937.750000  17112.050781  16833.199219  17086.250000   \n",
       "2021-12-28  17177.599609  17250.250000  17161.150391  17233.250000   \n",
       "2021-12-29  17220.099609  17285.949219  17176.650391  17213.599609   \n",
       "2021-12-30  17201.449219  17264.050781  17146.349609  17203.949219   \n",
       "2021-12-31  17244.500000  17400.800781  17238.500000  17354.050781   \n",
       "\n",
       "               Adj Close  volume  \n",
       "Date                              \n",
       "2020-01-01  12182.500000  304100  \n",
       "2020-01-02  12282.200195  407700  \n",
       "2020-01-03  12226.650391  428800  \n",
       "2020-01-06  11993.049805  396500  \n",
       "2020-01-07  12052.950195  447800  \n",
       "...                  ...     ...  \n",
       "2021-12-27  17086.250000  144800  \n",
       "2021-12-28  17233.250000  176000  \n",
       "2021-12-29  17213.599609  161700  \n",
       "2021-12-30  17203.949219  320800  \n",
       "2021-12-31  17354.050781  167000  \n",
       "\n",
       "[498 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company = '^NSEI'\n",
    "\n",
    "start = '2020-01-01'\n",
    "end = '2022-01-01'\n",
    "\n",
    "new_data = yf.download(company, start=start, end=end)\n",
    "new_data.rename(columns={'Open':'open','High':'high','Low':'low','Close':'close','Volume':'volume'}, inplace= True)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NP Hard Approch For Getting Best Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DO NOT RUNN\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from itertools import combinations\n",
    "\n",
    "# def find_best_attributes(attributes, current_set, best_set, best_accuracy, X_train, X_test, y_train, y_test):\n",
    "#     # Base case: check accuracy and update best set if needed\n",
    "#     if len(current_set) > 0:\n",
    "#         model = XGBClassifier()\n",
    "#         model.fit(X_train[current_set], y_train)\n",
    "#         pred_test = model.predict(X_test[current_set])\n",
    "#         acc_test = accuracy_score(y_test, pred_test)\n",
    "        \n",
    "#         if acc_test > best_accuracy[0]:\n",
    "#             best_accuracy[0] = acc_test\n",
    "#             best_set[0] = current_set.copy()\n",
    "\n",
    "#     # Recursive case: try adding each attribute and recurse\n",
    "#     for attribute in attributes:\n",
    "#         if attribute not in current_set:\n",
    "#             find_best_attributes(attributes, current_set + [attribute], best_set, best_accuracy, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# # Assuming df is your DataFrame containing both X and y\n",
    "# attributes = ['RSI', 'CCI', 'AO', 'MOM', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9', 'ATR',\n",
    "#                'BOP', 'RVI', 'DMP_16', 'DMN_16', 'STOCHk_14_3_3', 'STOCHd_14_3_3',\n",
    "#                'STOCHRSIk_16_14_3_3', 'STOCHRSId_16_14_3_3', 'WPR']\n",
    "\n",
    "# # Split your data into train and test sets\n",
    "# train_pct_index = int(0.7 * len(df))\n",
    "# X_train, X_test = df[attributes][:train_pct_index], df[attributes][train_pct_index:]\n",
    "# y_train, y_test = df['Target'][:train_pct_index], df['Target'][train_pct_index:]\n",
    "\n",
    "# best_set = [None]  # List to store the best set of attributes\n",
    "# best_accuracy = [0.0]  # List to store the best accuracy\n",
    "\n",
    "# # Start the recursive search\n",
    "# find_best_attributes(attributes, [], best_set, best_accuracy, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# # Print the results\n",
    "# print('Best Attribute Set:', best_set[0])\n",
    "# print('Best Accuracy:', best_accuracy[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best attributes according to the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/skywalker/MINOR/Prediction.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/skywalker/MINOR/Prediction.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m sfs \u001b[39m=\u001b[39m SequentialFeatureSelector(model, n_features_to_select\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m'\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/skywalker/MINOR/Prediction.ipynb#X26sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Fit on the training data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/skywalker/MINOR/Prediction.ipynb#X26sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m sfs\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/skywalker/MINOR/Prediction.ipynb#X26sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Get the selected features\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/skywalker/MINOR/Prediction.ipynb#X26sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m selected_features \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mcolumns[sfs\u001b[39m.\u001b[39mget_support()]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_selection/_sequential.py:248\u001b[0m, in \u001b[0;36mSequentialFeatureSelector.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    246\u001b[0m is_auto_select \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_to_select \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_iterations):\n\u001b[0;32m--> 248\u001b[0m     new_feature_idx, new_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_best_new_feature_score(\n\u001b[1;32m    249\u001b[0m         cloned_estimator, X, y, cv, current_mask\n\u001b[1;32m    250\u001b[0m     )\n\u001b[1;32m    251\u001b[0m     \u001b[39mif\u001b[39;00m is_auto_select \u001b[39mand\u001b[39;00m ((new_score \u001b[39m-\u001b[39m old_score) \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol):\n\u001b[1;32m    252\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_selection/_sequential.py:279\u001b[0m, in \u001b[0;36mSequentialFeatureSelector._get_best_new_feature_score\u001b[0;34m(self, estimator, X, y, cv, current_mask)\u001b[0m\n\u001b[1;32m    277\u001b[0m         candidate_mask \u001b[39m=\u001b[39m \u001b[39m~\u001b[39mcandidate_mask\n\u001b[1;32m    278\u001b[0m     X_new \u001b[39m=\u001b[39m X[:, candidate_mask]\n\u001b[0;32m--> 279\u001b[0m     scores[feature_idx] \u001b[39m=\u001b[39m cross_val_score(\n\u001b[1;32m    280\u001b[0m         estimator,\n\u001b[1;32m    281\u001b[0m         X_new,\n\u001b[1;32m    282\u001b[0m         y,\n\u001b[1;32m    283\u001b[0m         cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    284\u001b[0m         scoring\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscoring,\n\u001b[1;32m    285\u001b[0m         n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    286\u001b[0m     )\u001b[39m.\u001b[39mmean()\n\u001b[1;32m    287\u001b[0m new_feature_idx \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(scores, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m feature_idx: scores[feature_idx])\n\u001b[1;32m    288\u001b[0m \u001b[39mreturn\u001b[39;00m new_feature_idx, scores[new_feature_idx]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    560\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 562\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    563\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    564\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    565\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    566\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    567\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    568\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    569\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    570\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    571\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    572\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    573\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    574\u001b[0m )\n\u001b[1;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    311\u001b[0m         clone(estimator),\n\u001b[1;32m    312\u001b[0m         X,\n\u001b[1;32m    313\u001b[0m         y,\n\u001b[1;32m    314\u001b[0m         scorers,\n\u001b[1;32m    315\u001b[0m         train,\n\u001b[1;32m    316\u001b[0m         test,\n\u001b[1;32m    317\u001b[0m         verbose,\n\u001b[1;32m    318\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    319\u001b[0m         fit_params,\n\u001b[1;32m    320\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    321\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    322\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    323\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    324\u001b[0m     )\n\u001b[1;32m    325\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m indices\n\u001b[1;32m    326\u001b[0m )\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    727\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    728\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 729\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    731\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1515\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1487\u001b[0m (\n\u001b[1;32m   1488\u001b[0m     model,\n\u001b[1;32m   1489\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1495\u001b[0m )\n\u001b[1;32m   1496\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1497\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1498\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1512\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[1;32m   1513\u001b[0m )\n\u001b[0;32m-> 1515\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1516\u001b[0m     params,\n\u001b[1;32m   1517\u001b[0m     train_dmatrix,\n\u001b[1;32m   1518\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1519\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1520\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1521\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1522\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1523\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1524\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1525\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1526\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1527\u001b[0m )\n\u001b[1;32m   1529\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1530\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py:2050\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2048\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2049\u001b[0m     _check_call(\n\u001b[0;32m-> 2050\u001b[0m         _LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\n\u001b[1;32m   2051\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, ctypes\u001b[39m.\u001b[39;49mc_int(iteration), dtrain\u001b[39m.\u001b[39;49mhandle\n\u001b[1;32m   2052\u001b[0m         )\n\u001b[1;32m   2053\u001b[0m     )\n\u001b[1;32m   2054\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2055\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Find best attributes using inbuilt functions\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.feature_selection import SequentialFeatureSelector\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# attributes = ['RSI', 'CCI', 'AO', 'MOM', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9', 'ATR',\n",
    "#               'BOP', 'RVI', 'DMP_16', 'DMN_16', 'STOCHk_14_3_3', 'STOCHd_14_3_3',\n",
    "#               'STOCHRSIk_16_14_3_3', 'STOCHRSId_16_14_3_3', 'WPR']\n",
    "\n",
    "# X = df[attributes]\n",
    "# y = df['Target']\n",
    "\n",
    "# train_pct_index = int(0.7 * len(X))\n",
    "# X_train, X_test = X[:train_pct_index], X[train_pct_index:]\n",
    "# y_train, y_test = y[:train_pct_index], y[train_pct_index:]\n",
    "\n",
    "# # Define the XGBoost model\n",
    "# model = XGBClassifier()\n",
    "\n",
    "# # Sequential Feature Selector\n",
    "# sfs = SequentialFeatureSelector(model, n_features_to_select=5, direction='forward', cv=5)\n",
    "\n",
    "# # Fit on the training data\n",
    "# sfs.fit(X_train, y_train)\n",
    "\n",
    "# # Get the selected features\n",
    "# selected_features = X_train.columns[sfs.get_support()]\n",
    "\n",
    "# # Print the selected features\n",
    "# print('Selected Features:', selected_features)\n",
    "\n",
    "# # Train the model on the selected features\n",
    "# model.fit(X_train[selected_features], y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# pred_train = model.predict(X_train[selected_features])\n",
    "# pred_test = model.predict(X_test[selected_features])\n",
    "\n",
    "# # Evaluate the model\n",
    "# acc_train = accuracy_score(y_train, pred_train)\n",
    "# acc_test = accuracy_score(y_test, pred_test)\n",
    "# print('****Train Results****')\n",
    "# print(\"Accuracy: {:.4%}\".format(acc_train))\n",
    "# print('****Test Results****')\n",
    "# print(\"Accuracy: {:.4%}\".format(acc_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11774     0     0]\n",
      " [  962   328     0]\n",
      " [  965     2   367]]\n",
      "[[4979   11   23]\n",
      " [ 552    0    1]\n",
      " [ 598    1    7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      1.00      0.92     11774\n",
      "         1.0       0.99      0.25      0.40      1290\n",
      "         2.0       1.00      0.28      0.43      1334\n",
      "\n",
      "    accuracy                           0.87     14398\n",
      "   macro avg       0.95      0.51      0.59     14398\n",
      "weighted avg       0.88      0.87      0.83     14398\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.99      0.89      5013\n",
      "         1.0       0.00      0.00      0.00       553\n",
      "         2.0       0.23      0.01      0.02       606\n",
      "\n",
      "    accuracy                           0.81      6172\n",
      "   macro avg       0.35      0.33      0.31      6172\n",
      "weighted avg       0.68      0.81      0.73      6172\n",
      "\n",
      "['RSI', 'CCI', 'BOP', 'STOCHRSIk_16_14_3_3', 'WPR']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "matrix_train = confusion_matrix(y_train, pred_train)\n",
    "matrix_test = confusion_matrix(y_test, pred_test)\n",
    "\n",
    "print(matrix_train)\n",
    "print(matrix_test)\n",
    "\n",
    "report_train = classification_report(y_train, pred_train)\n",
    "report_test = classification_report(y_test, pred_test)\n",
    "\n",
    "print(report_train)\n",
    "print(report_test)\n",
    "#choices = [2, 0, -1, +1]\n",
    "##choices = [2, 0, 3, +1]\n",
    "print(model.get_booster().feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RSI', 'CCI', 'BOP', 'STOCHRSIk_16_14_3_3', 'WPR']\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "from xgboost import plot_importance\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "#pyplot.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "#plot feature importance\n",
    "plot_importance(model)\n",
    "pyplot.show()\n",
    "print(model.get_booster().feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from itertools import combinations\n",
    "\n",
    "# def find_best_attributes(attributes, current_set, best_set, best_accuracy, X_train, X_test, y_train, y_test):\n",
    "#     # Base case: check accuracy and update best set if needed\n",
    "#     if len(current_set) > 0:\n",
    "#         model = XGBClassifier()\n",
    "#         model.fit(X_train[current_set], y_train)\n",
    "#         pred_test = model.predict(X_test[current_set])\n",
    "#         acc_test = accuracy_score(y_test, pred_test)\n",
    "        \n",
    "#         if acc_test > best_accuracy[0]:\n",
    "#             best_accuracy[0] = acc_test\n",
    "#             best_set[0] = current_set.copy()\n",
    "#         print('Current Best Attribute Set:', best_set[0])\n",
    "#         print('Current Best Accuracy:', best_accuracy[0])\n",
    "\n",
    "#     # Recursive case: try adding each attribute and recurse\n",
    "#     for attribute in attributes:\n",
    "#         if attribute not in current_set:\n",
    "#             find_best_attributes(attributes, current_set + [attribute], best_set, best_accuracy, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# # Assuming df is your DataFrame containing both X and y\n",
    "# attributes = ['RSI', 'CCI', 'AO', 'MOM', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9', 'ATR',\n",
    "#                'BOP', 'RVI', 'DMP_16', 'DMN_16', 'STOCHk_14_3_3', 'STOCHd_14_3_3',\n",
    "#                'STOCHRSIk_16_14_3_3', 'STOCHRSId_16_14_3_3', 'WPR']\n",
    "\n",
    "# # Split your data into train and test sets\n",
    "# train_pct_index = int(0.7 * len(df))\n",
    "# X_train, X_test = df[attributes][:train_pct_index], df[attributes][train_pct_index:]\n",
    "# y_train, y_test = df['Target'][:train_pct_index], df['Target'][train_pct_index:]\n",
    "\n",
    "# best_set = [None]  # List to store the best set of attributes\n",
    "# best_accuracy = [0.0]  # List to store the best accuracy\n",
    "\n",
    "# # Start the recursive search\n",
    "# find_best_attributes(attributes, [], best_set, best_accuracy, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# # Print the final results\n",
    "# print('Best Attribute Set:', best_set[0])\n",
    "# print('Best Accuracy:', best_accuracy[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
